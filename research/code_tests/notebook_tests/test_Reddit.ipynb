{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4924761d",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Test the Reddit data collection class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ca42a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d4cf6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# Environmental variables\n",
    "import dotenv\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Reddit class\n",
    "reddit_class_path = '../../../code/reddit'\n",
    "sys.path.insert(0, reddit_class_path)\n",
    "import reddit_data_fetcher as rdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31c114",
   "metadata": {},
   "source": [
    "## Check the logic for cleaning keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebfe42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_keyword_text(text):\n",
    "    '''\n",
    "    Method to clean Reddit and keyword texts in either the original post\n",
    "    or associated comments.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Remove these words from search terms\n",
    "    stop_words = ['stop', 'the', 'to', 'and', 'a', 'in', 'it',\n",
    "                  'is', 'I', 'i', 'that', 'had', 'on', 'for', 'were', 'was',\n",
    "                  'through', 'of', 'way', 'end', 'our', 'place', 'home',\n",
    "                  'support', 'city', 'visitor', 'women', 'men', 'need', 'idea',\n",
    "                  'north', 'south', 'east', 'west', 'ready', 'save', 'salt', 'win',\n",
    "                  'lose', 'loss', 'family', 'working', 'hope', 'love', 'house']\n",
    "\n",
    "#     # Split words with some characters\n",
    "# #     pat = r\"\\/\"\n",
    "#     pat = \"\\\\/\"\n",
    "#     text = re.sub(pat, ' ', text)\n",
    "\n",
    "    # Remove unwanted characters\n",
    "\n",
    "    pat = r\"\\\\n|r/|[^a-zA-Z0-9 ]\"\n",
    "    text = re.sub(pat, ' ', text)\n",
    "\n",
    "    # cohvert to lowercase\n",
    "    text = text.strip().lower()\n",
    "\n",
    "    # Remove stop words\n",
    "    pat = \"|\".join([\"\\\\b{}\\\\b\".format(w) for w in stop_words])\n",
    "    text = re.sub(pat, ' ', text)\n",
    "\n",
    "    # remove extra spaces\n",
    "    pat = r\"\\s{2,}\"\n",
    "    text = re.sub(pat, ' ', text)\n",
    "\n",
    "    # Remove leading and trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eab0dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_file_path = '../../../data/keywords'\n",
    "keywords_files = ['ac.csv']\n",
    "\n",
    "keywords = []\n",
    "\n",
    "# read each file with keywords\n",
    "for kwf in keywords_files:\n",
    "\n",
    "    # Read the files into a dataframe\n",
    "    df_kw = pd.read_csv(os.path.join(keywords_file_path, kwf), index_col=0)\n",
    "\n",
    "    # Get the cleaned keywords\n",
    "    keywords.extend([clean_keyword_text(k) for k in df_kw[df_kw.columns[0]].tolist()])\n",
    "\n",
    "# Ensure keywords are strings and remove any duplicates\n",
    "search_terms = [k for k in set(keywords) if isinstance(k, str) and len(k) > 1]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b77e173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esquimalt nation office',\n",
       " 'greater victoria placemaking network',\n",
       " 'first metropolitan united church',\n",
       " 'cool aid society',\n",
       " 'burnside gorge community association',\n",
       " 'society st vincent de paul',\n",
       " 'greater yyj politics',\n",
       " 'society',\n",
       " 'peers victoria resources society',\n",
       " 'svdp',\n",
       " 'rentsmart',\n",
       " 'achievement foundation victoria',\n",
       " 'victoria harbour cats',\n",
       " 'victoria tenant action group',\n",
       " 'greater victoria coalition homelessness',\n",
       " 'avi',\n",
       " 'tenant action group victoria',\n",
       " 'quadra village community centre',\n",
       " 'red cedar caf',\n",
       " 'workbc centre victoria',\n",
       " 'vancouver island mental health society',\n",
       " 'aehcr',\n",
       " 'district saanich',\n",
       " 'sanctuary youth centre',\n",
       " 'greater victoria acting together',\n",
       " 'spring exchange',\n",
       " 'oak bay united church',\n",
       " 'victoria aids resource community services',\n",
       " 'mental health society greater victoria',\n",
       " 'james bay community project',\n",
       " 'existence project',\n",
       " 'victoria s transition',\n",
       " 'victoria court youth justice committee',\n",
       " 'victoria youth council',\n",
       " 'upstream prevent youth homelessness',\n",
       " 'park neighbourhood association',\n",
       " 'boys girls club vanouver island',\n",
       " 'backpack project victoria bc',\n",
       " 'victoria police department',\n",
       " 'john howard society victoria',\n",
       " 'greater victoria housing society',\n",
       " 'makola housing society',\n",
       " 'john howard society',\n",
       " 'victoria s o s',\n",
       " 'literacy victoria',\n",
       " 'safer victoria',\n",
       " 'bc housing',\n",
       " 'npna',\n",
       " 'saanich police community engagement division',\n",
       " 'mental health recovery partners island',\n",
       " 'saanich police department',\n",
       " 'community social planning council',\n",
       " 'aceh',\n",
       " 'extreme outreach society coffee',\n",
       " 'victoria foundation',\n",
       " 'yyj tenants union',\n",
       " 'township esquimalt',\n",
       " 'university victoria',\n",
       " 'anawin companion society',\n",
       " 'victoria brain injury society',\n",
       " 'umbrella society',\n",
       " 'tourism vancouver island',\n",
       " 'sooke transition society',\n",
       " 'dvba',\n",
       " 'solid outreach',\n",
       " 'cridge centre',\n",
       " 'aryze developments',\n",
       " 'aboriginal coalition homelessness',\n",
       " 'downtown victoria business association',\n",
       " 'islandcommha',\n",
       " 'victoria chamber',\n",
       " 'victoria downtown residents association',\n",
       " 'corporation township esquimalt',\n",
       " 'mustard seed',\n",
       " 'aids vancouver island',\n",
       " 'avivanisle',\n",
       " 'vwth',\n",
       " 'anawim',\n",
       " 'victoria placemaking',\n",
       " 'togethervic',\n",
       " 'hillsidequadra',\n",
       " 'crd',\n",
       " 'foundry victoria',\n",
       " 'beacon hill park',\n",
       " 'habitat humanity victoria',\n",
       " 'victoria',\n",
       " 'st john ambulance',\n",
       " 'island health',\n",
       " 'central saanich police service',\n",
       " 'united southern vancouver island',\n",
       " 'victoria disability resource centre',\n",
       " 'pacifica housing',\n",
       " 'colwood',\n",
       " 'capital regional district',\n",
       " 'salvation army victoria arc',\n",
       " 'soap victoria',\n",
       " 'westshore chamber commerce',\n",
       " 'restorative justice victoria',\n",
       " 'substance uvic',\n",
       " 'gvceh',\n",
       " 'victoria real estate board',\n",
       " 'vtag',\n",
       " 'vibrant victoria',\n",
       " 'need2 suicide prevention education',\n",
       " 'sooke homelessness coalition',\n",
       " 'town view royal',\n",
       " 'beacon community services',\n",
       " 'homeless podcast',\n",
       " 'rotary club victoria',\n",
       " 'fernwood community association',\n",
       " 'alliance homelessness capital region',\n",
       " 'first peoples victoria',\n",
       " 'destination greater victoria center',\n",
       " 'island centre counselling training',\n",
       " 'homelessness services association bc',\n",
       " '1up victoria single parent resource centre',\n",
       " 'victoria sexual assault centre',\n",
       " 'vandu',\n",
       " 'victoria native friendship centre',\n",
       " 'young parents',\n",
       " 'vreb']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35796a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'addicted addict pppp newline'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"addicted/addict\"\n",
    "clean_keyword_text(test_text)\n",
    "\n",
    "test_text = \"addicted/addict$#pppp-newline/r/\"\n",
    "clean_keyword_text(test_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57f4dd",
   "metadata": {},
   "source": [
    "## Test the Reddit crawler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d5467d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv('../../../data/environment/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a630ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2024-02-15 14:02:54: event: start fetch: subreddit_name: britishcolumbia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephengodfrey/anaconda3/envs/gvceh/lib/python3.10/site-packages/asyncpraw/models/reddit/base.py:40: RuntimeWarning: coroutine 'GVCEHReddit.fetch_data' was never awaited\n",
      "  raise AttributeError(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2024-02-15 14:04:09: event: fetch complete\n"
     ]
    }
   ],
   "source": [
    "# Attributes to modify using the **kwargs parameter\n",
    "posts_file_path = \"../../data_tests/reddit_tests/posts\"\n",
    "logs_file_path = \"../../data_tests/reddit_tests/logs\"\n",
    "keywords_file_path = '../../../data/keywords'\n",
    "limit_num=10\n",
    "\n",
    "\n",
    "# Initialize Reddit object\n",
    "data_fetcher = rdf.GVCEHReddit(client_id=os.environ.get(\"REDDIT_CLIENT_ID\"),\n",
    "                              client_secret=os.environ.get(\"REDDIT_CLIENT_SECRET\"),\n",
    "                              user_agent=os.environ.get(\"REDDIT_USER_AGENT\"),\n",
    "                              posts_file_path=posts_file_path,\n",
    "                              logs_file_path=logs_file_path,\n",
    "                              keywords_file_path=keywords_file_path,\n",
    "                              limit_num=limit_num)\n",
    "\n",
    "#Define subreddits to search\n",
    "subreddit_names = ['britishcolumbia']\n",
    "\n",
    "await data_fetcher.fetch_data(subreddit_names=subreddit_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2fb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d030f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb46e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
